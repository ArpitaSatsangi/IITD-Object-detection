# -*- coding: utf-8 -*-
"""00 pytorch frcnn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lDJ5Obh9i8ZzI5lKy5CLGmzG5tDZali6
"""

pip install torch torchvision pillow

import torch
import torchvision
from torchvision.models.detection import FasterRCNN
from torchvision.transforms import functional as F
from PIL import Image, ImageDraw


# Load pre-trained Faster R-CNN model
model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)
model.eval()

# Load PASCAL VOC dataset
dataset = torchvision.datasets.VOCDetection(root='./VOCdevkit', year='2007', image_set='trainval', download=True)

def detect_objects(image):
    # Transform image to tensor
    image_tensor = F.to_tensor(image)
    image_tensor = torch.unsqueeze(image_tensor, 0)

    # Run object detection
    with torch.no_grad():
        predictions = model(image_tensor)

    boxes = predictions[0]['boxes'].tolist()
    labels = predictions[0]['labels'].tolist()
    scores = predictions[0]['scores'].tolist()

    return boxes, labels, scores

def main():
    for i in range(len(dataset)):
        image, target = dataset.__getitem__(i)
        image = image.convert('RGB')
        boxes, labels, scores = detect_objects(image)

        # Draw bounding boxes and labels on the image
        draw = ImageDraw.Draw(image)
        for box, label, score in zip(boxes, labels, scores):
            if score > 0.5:  # Filter detections by confidence threshold
                x1, y1, x2, y2 = box
                draw.rectangle([(x1, y1), (x2, y2)], outline='red', width=2)
                draw.text((x1, y1 - 10), str(label), fill='red')

        # Display the image
        image.show()

if __name__ == '__main__':
    main()

import torch
import torchvision
from torchvision.transforms import functional as F
from PIL import Image, ImageDraw


# Load pre-trained Faster R-CNN model
model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)
model.eval()

# Load PASCAL VOC dataset
dataset = torchvision.datasets.VOCDetection(root='./VOCdevkit', year='2007', image_set='trainval', download=True)

def detect_objects(image):
    # Transform image to tensor
    image_tensor = F.to_tensor(image)
    image_tensor = torch.unsqueeze(image_tensor, 0)

    # Run object detection
    with torch.no_grad():
        predictions = model(image_tensor)

    boxes = predictions[0]['boxes'].tolist()
    labels = predictions[0]['labels'].tolist()
    scores = predictions[0]['scores'].tolist()

    return boxes, labels, scores

def main():
    for i in range(len(dataset)):
        image, target = dataset.__getitem__(i)
        image = image.convert('RGB')
        boxes, labels, scores = detect_objects(image)

        # Draw bounding boxes and labels on the image
        draw = ImageDraw.Draw(image)
        for box, label, score in zip(boxes, labels, scores):
            if score > 0.5:  # Filter detections by confidence threshold
                x1, y1, x2, y2 = box
                draw.rectangle([(x1, y1), (x2, y2)], outline='red', width=2)

                # Write label on top of the bounding box
                label_text = f"{label}: {score:.2f}"
                text_width, text_height = draw.textsize(label_text)
                draw.rectangle([(x1, y1), (x1 + text_width, y1 + text_height)], fill='red')
                draw.text((x1, y1), label_text, fill='white')

        # Display the image
        image.show()

if __name__ == '__main__':
    main()

'''
import torch
import torchvision
from torchvision.transforms import functional as F
from PIL import Image, ImageDraw
import xml.etree.ElementTree as ET


# Load pre-trained Faster R-CNN model
model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)
model.eval()

# Load PASCAL VOC dataset
dataset = torchvision.datasets.VOCDetection(root='./VOCdevkit', year='2012', image_set='trainval', download=True)

# Function to extract class labels from annotation files
def get_class_labels(annotation):
    tree = ET.parse(annotation)
    objects = tree.findall('object')
    classes = []
    for obj in objects:
        class_name = obj.find('name').text
        classes.append(class_name)
    return classes

def detect_objects(image):
    # Transform image to tensor
    image_tensor = F.to_tensor(image)
    image_tensor = torch.unsqueeze(image_tensor, 0)

    # Run object detection
    with torch.no_grad():
        predictions = model(image_tensor)

    boxes = predictions[0]['boxes'].tolist()
    labels = predictions[0]['labels'].tolist()
    scores = predictions[0]['scores'].tolist()

    return boxes, labels, scores

def main():
    for i in range(len(dataset)):
        image, target = dataset.__getitem__(i)
        image = image.convert('RGB')
        boxes, labels, scores = detect_objects(image)

        # Draw bounding boxes and labels on the image
        draw = ImageDraw.Draw(image)
        annotation_path = dataset.annotations[i]
        class_labels = get_class_labels(annotation_path)
        for box, label, score in zip(boxes, labels, scores):
            if score > 0.5:  # Filter detections by confidence threshold
                x1, y1, x2, y2 = box
                draw.rectangle([(x1, y1), (x2, y2)], outline='red', width=2)

                # Write label on top of the bounding box
                if label < len(class_labels):
                    class_name = class_labels[label]
                    label_text = f"{class_name}: {score:.2f}"
                    text_width, text_height = draw.textsize(label_text)
                    draw.rectangle([(x1, y1), (x1 + text_width, y1 + text_height)], fill='red')
                    draw.text((x1, y1), label_text, fill='white')

        # Display the image
        image.show()

if __name__ == '__main__':
    main()
'''